{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8c1cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2644ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets\n",
    "\n",
    "gold_data = \"datasets/goldData.csv\"\n",
    "reg_data = \"datasets/regressionData.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "519a45f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>21.549452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>47.464463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.218656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>36.586398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>87.288984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x          y\n",
       "0  24.0  21.549452\n",
       "1  50.0  47.464463\n",
       "2  15.0  17.218656\n",
       "3  38.0  36.586398\n",
       "4  87.0  87.288984"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"datasets/regressionData.csv\").head()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6004a65",
   "metadata": {},
   "source": [
    "# Intro to pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89005098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a881e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b312170",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Gold\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fd7155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Gold</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11c32d0a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8368ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|_c0|        _c1|\n",
      "+---+-----------+\n",
      "|  x|          y|\n",
      "| 24|21.54945196|\n",
      "| 50|47.46446305|\n",
      "| 15|17.21865634|\n",
      "| 38|36.58639803|\n",
      "| 87|87.28898389|\n",
      "| 36|32.46387493|\n",
      "| 12|10.78089683|\n",
      "| 81| 80.7633986|\n",
      "| 25|24.61215147|\n",
      "|  5|6.963319071|\n",
      "| 16|11.23757338|\n",
      "| 16|13.53290206|\n",
      "| 24|24.60323899|\n",
      "| 39|39.40049976|\n",
      "| 54|48.43753838|\n",
      "| 60|61.69900319|\n",
      "| 26|26.92832418|\n",
      "| 73| 70.4052055|\n",
      "| 29|29.34092408|\n",
      "+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('datasets/regressionData.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f00a52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|  x|          y|\n",
      "+---+-----------+\n",
      "| 24|21.54945196|\n",
      "| 50|47.46446305|\n",
      "| 15|17.21865634|\n",
      "| 38|36.58639803|\n",
      "| 87|87.28898389|\n",
      "| 36|32.46387493|\n",
      "| 12|10.78089683|\n",
      "| 81| 80.7633986|\n",
      "| 25|24.61215147|\n",
      "|  5|6.963319071|\n",
      "| 16|11.23757338|\n",
      "| 16|13.53290206|\n",
      "| 24|24.60323899|\n",
      "| 39|39.40049976|\n",
      "| 54|48.43753838|\n",
      "| 60|61.69900319|\n",
      "| 26|26.92832418|\n",
      "| 73| 70.4052055|\n",
      "| 29|29.34092408|\n",
      "| 31|25.30895192|\n",
      "+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('datasets/regressionData.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "516eb73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "864faf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(x='24', y='21.54945196'),\n",
       " Row(x='50', y='47.46446305'),\n",
       " Row(x='15', y='17.21865634')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "928857bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()  #same like df.info in pandas but note that every variable is considered as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3df4f",
   "metadata": {},
   "source": [
    "# More into pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d34e2404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lets define the dataset column type \n",
    "df_pyspark = spark.read.option('header', 'true').csv('datasets/regressionData.csv', inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ee70965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or there is a shorter way to read\n",
    "\n",
    "df_pyspark = spark.read.csv('datasets/regressionData.csv', header=True, inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb198cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get colomns\n",
    "df = df_pyspark    # Just coping it to get a shorter name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ee9ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|   x|\n",
      "+----+\n",
      "|24.0|\n",
      "|50.0|\n",
      "|15.0|\n",
      "+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('x').show(3)   # just getting a column, it is a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c86f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|   x|          y|\n",
      "+----+-----------+\n",
      "|24.0|21.54945196|\n",
      "|50.0|47.46446305|\n",
      "|15.0|17.21865634|\n",
      "+----+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['x', 'y']).show(3)   # multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18142b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+------------------+----------+\n",
      "|               Date|      Open|      High|               Low|     Close|\n",
      "+-------------------+----------+----------+------------------+----------+\n",
      "|2011-12-15 00:00:00|154.740005|154.949997|151.71000700000005|152.330002|\n",
      "|2011-12-16 00:00:00|154.309998|155.369995|        153.899994|155.229996|\n",
      "|2011-12-19 00:00:00|155.479996|155.860001|        154.360001|154.869995|\n",
      "|2011-12-20 00:00:00|156.820007|157.429993|        156.580002|156.979996|\n",
      "|2011-12-21 00:00:00|156.979996|157.529999|        156.130005|157.160004|\n",
      "+-------------------+----------+----------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the second dataset\n",
    "df2 = spark.read.csv(gold_data, header=True, inferSchema=True).select(['Date','Open','High','Low','Close'])\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e8390bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'timestamp'),\n",
       " ('Open', 'double'),\n",
       " ('High', 'double'),\n",
       " ('Low', 'double'),\n",
       " ('Close', 'double')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes   # checking datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a744d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|              Open|              High|               Low|             Close|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|              1718|              1718|              1718|              1718|\n",
      "|   mean|127.32343424039563|127.85423744179249|126.77769494412128|127.31948200349262|\n",
      "| stddev| 17.52699325106065| 17.63118930056491|17.396513028739353| 17.53626908041546|\n",
      "|    min|        100.919998|        100.989998|        100.230003|             100.5|\n",
      "|    max|        173.199997|        174.070007|        172.919998|        173.610001|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1bc506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()   # Count on how many samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09dbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
